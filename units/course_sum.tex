\section{סיכום הקורס: סטטיסטיקה לפסיכולוגים א׳}

קורס זה עסק במעבר מתיאור נתונים למדידה פורמלית של אי־ודאות,
ובהסקה על אוכלוסייה מתוך מדגם.
המהלך המרכזי של הקורס הוא בניית מסגרת מתמטית
להערכת סבירות, קבלת החלטות, והבנת מגבלות הידע המדגמי.

הקורס מתחלק רעיונית לארבעה צירים מרכזיים:
תיאור נתונים, הסתברות והתפלגויות,
התפלגות הדגימה והיסק סטטיסטי,
וביקורת על בדיקת השערות תוך שימוש בכלים משלימים.

\subsection{ציר ראשון: תיאור נתונים}

בשלב הראשון נלמדו כלים לתיאור מדגם:

\begin{itemize}
\item מדדי נטייה מרכזית: ממוצע, חציון, שכיח
\item מדדי פיזור: שונות וסטיית תקן
\item ייצוגים גרפיים: היסטוגרמה, תרשימי פיזור
\end{itemize}

השונות הוגדרה כמדד לפיזור סביב הממוצע:
\[
Var(X) = E[(X-\mu)^2]
\]
וריבוע הסטיות נועד למנוע ביטול סימנים
ולהדגיש חריגות גדולות.

\subsection{ציר שני: הסתברות והתפלגויות}

נלמדה ההתפלגות הנורמלית ככלי יסוד:
\[
X \sim N(\mu,\sigma^2)
\]

שינוי תוחלת \(\mu\) מזיז את ההתפלגות,
ושינוי סטיית התקן \(\sigma\) מותח או מכווץ אותה,
אך הצורה הנורמלית נשמרת.

ההתפלגות הנורמלית הסטנדרטית הוגדרה כ:
\[
Z = \frac{X-\mu}{\sigma} \sim N(0,1)
\]

תקנון שומר על שטחי הסתברות,
ולכן מאפשר חישוב הסתברויות אחיד באמצעות טבלת \(Z\).

\subsection{ציר שלישי: התפלגות הדגימה}

נקודת המפנה בקורס היא המעבר מתצפיות בודדות
לסטטיסטי מדגם.

ממוצע המדגם הוגדר כמשתנה מקרי:
\[
\bar X = \frac{1}{n}\sum_{i=1}^n X_i
\]

כאשר \(X_1,\dots,X_n\) הם תצפיות מקריות בלתי־תלויות מאותה אוכלוסייה,
מתקיים:
\[
E[\bar X] = \mu
\qquad
Var(\bar X) = \frac{\sigma^2}{n}
\]

סטיית התקן של התפלגות הדגימה נקראת \textbf{טעות התקן}:
\[
\sigma_{\bar X} = \frac{\sigma}{\sqrt n}
\]

ככל ש-\(n\) גדל, התפלגות הדגימה נעשית צרה יותר,
וממוצעי מדגם נעשים יציבים יותר.

\subsubsection{משפט הגבול המרכזי}

כאשר \(n\) גדול דיו,
התפלגות הדגימה של הממוצעים היא נורמלית בקירוב,
ללא קשר לצורת ההתפלגות באוכלוסייה.

זהו משפט עמוק ולא טריוויאלי,
שהוכחתו שייכת לקורסים מתמטיים מתקדמים,
ונשענת על תכונות של סכומי משתנים מקריים.

\subsection{ציר רביעי: בדיקת השערות}

בדיקת השערות נועדה לענות על השאלה:
\begin{quote}
עד כמה הנתונים קיצוניים בהנחה שהשערת האפס נכונה?
\end{quote}

סטטיסטי המבחן לממוצע (כאשר \(\sigma\) ידועה):
\[
Z = \frac{\bar X - \mu_0}{\sigma/\sqrt n}
\]

ה-\(p\)-value מוגדר כהסתברות לקבל תוצאה קיצונית לפחות כמו הנצפית,
\textbf{בהינתן שהשערת האפס נכונה}:
\[
p = P(|Z| \ge |z_{\text{obs}}| \mid H_0)
\]

בדיקת השערות כוללת שתי טעויות אפשריות:
\begin{itemize}
\item טעות מסוג I: דחיית \(H_0\) כאשר היא נכונה (\(\alpha\))
\item טעות מסוג II: אי־דחיית \(H_0\) כאשר \(H_1\) נכונה (\(\beta\))
\end{itemize}

\subsubsection{עוצמת המבחן}

עוצמת המבחן מוגדרת כ:
\[
\text{Power} = 1-\beta
\]

והיא ההסתברות לגלות אפקט אמיתי.
עוצמה מוגדרת \textbf{רק תחת ההנחה ש-\(H_1\) נכונה},
והיא תכונה של תכנון המחקר — לא של המדגם הספציפי.

\subsection{ביקורת על NHST}

בדיקת השערות מספקת החלטה בינארית,
אך סובלת ממגבלות:
\begin{itemize}
\item תלות חזקה בגודל המדגם
\item חוסר מידע על גודל האפקט
\item שרירותיות סף המובהקות
\end{itemize}

מובהקות סטטיסטית אינה שקולה לחשיבות מעשית.

\subsection{כלים משלימים: גודל אפקט ורווח סמך}

גודל אפקט מודד \textbf{כמה גדול} ההבדל.
דוגמה נפוצה:
\[
d = \frac{\mu_1-\mu_0}{\sigma}
\]

רווח סמך מספק טווח ערכים סבירים לפרמטר:
\[
\bar X \pm Z_{\alpha/2}\frac{\sigma}{\sqrt n}
\]

רווח סמך דו־צדדי ברמת סמך \(1-\alpha\)
שקול לבדיקת השערות דו־צדדית ברמת מובהקות \(\alpha\),
אך מספק מידע עשיר יותר על אי־הוודאות וגודל האפקט.

\subsection{שורת סיום}

סטטיסטיקה אינה עוסקת בוודאות,
אלא בניהול אי־ודאות.

בדיקה סטטיסטית טובה משלבת:
\begin{itemize}
\item הבנת ההתפלגות והדגימה
\item החלטה פורמלית
\item הערכת גודל אפקט
\item הצגת אי־ודאות
\end{itemize}

זהו ההבדל בין תוצאה מובהקת
לבין הבנה סטטיסטית אמיתית.